{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6108d638",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62b512e-167b-4d96-a33f-3561ad2d99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hypergrad as hg\n",
    "from itertools import repeat\n",
    "from poi_util import poison_dataset,patching_test\n",
    "import poi_util\n",
    "import dataset_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586bc6e8-cdb9-42ce-bcff-672b65c68704",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "def get_results(model, criterion, data_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.long())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        return correct / total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4eaf2210",
   "metadata": {},
   "source": [
    "## Load dataset & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c7307a-b8eb-46b8-a438-c0066540ef52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "CIFAR10::init - doNormalization is True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_933886/2094017096.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = torch.Tensor(y_test.reshape((-1,)).astype(np.int))\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('==> Preparing data..')\n",
    "from torchvision.datasets import CIFAR10\n",
    "root = './datasets'\n",
    "dataset = dataset_utils.load_dataset('cifar10')(batch_size=200, doNormalization=True, inj_rate=0.9)\n",
    "#testset = CIFAR10(root, train=False, transform=None, download=True)\n",
    "x_test, y_test = dataset.test.data, dataset.test.targets\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "#attack_name = 'badnets'\n",
    "#target_lab = '8'\n",
    "#x_poi_test,y_poi_test= patching_test(x_test, y_test, attack_name, target_lab=target_lab)\n",
    "\n",
    "y_test = torch.Tensor(y_test.reshape((-1,)).astype(np.int))\n",
    "#y_poi_test = torch.Tensor(y_poi_test.reshape((-1,)).astype(np.int))\n",
    "\n",
    "x_test = torch.Tensor(np.transpose(x_test,(0,3,1,2)))\n",
    "#x_poi_test = torch.Tensor(np.transpose(x_poi_test,(0,3,1,2)))\n",
    "\n",
    "x_test[:,0] = (x_test[:,0]-0.485)/0.229\n",
    "x_test[:,1] = (x_test[:,1]-0.456)/0.224\n",
    "x_test[:,2] = (x_test[:,2]-0.406)/0.225\n",
    "\n",
    "test_set = TensorDataset(x_test[5000:],y_test[5000:])\n",
    "unl_set = TensorDataset(x_test[:5000],y_test[:5000])\n",
    "#att_val_set = TensorDataset(x_poi_test[:5000],y_poi_test[:5000])\n",
    "\n",
    "#data loader for verifying the clean test accuracy\n",
    "clnloader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=200, shuffle=False, num_workers=2)\n",
    "\n",
    "#data loader for verifying the attack success rate\n",
    "poiloader_cln = torch.utils.data.DataLoader(\n",
    "    unl_set, batch_size=200, shuffle=False, num_workers=2)\n",
    "\n",
    "#poiloader = torch.utils.data.DataLoader(\n",
    "#    att_val_set, batch_size=200, shuffle=False, num_workers=2)\n",
    "poiloader = dataset.test_backdoor_loader\n",
    "\n",
    "#data loader for the unlearning step\n",
    "unlloader = torch.utils.data.DataLoader(\n",
    "    unl_set, batch_size=200, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3332f2-8325-47c0-82ba-64cfe7b57816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_size = 32\n",
    "sdn_model = utils.get_sdn_model('vgg16',utils.get_add_output('vgg16'),num_classes, input_size)\n",
    "sdn_model.load_state_dict(torch.load('../BackdoorSDN/models/vgg16_cifar10/copy1/copy5/retrain_sdn_5.pt', map_location=device))\n",
    "sdn_model.eval()\n",
    "sdn_model.to(device=device)\n",
    "model = utils.sdn_to_cnn(sdn_model, device)\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e69e2f6",
   "metadata": {},
   "source": [
    "## Backdoor unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64374b4c-4f48-4629-9d32-8370c4dc1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_opt = torch.optim.Adam(params=model.parameters(),lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ecde8d-54b5-42c9-bffe-2911ff90b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ACC: 0.89\n",
      "Original ASR: 0.00044444444444444447\n"
     ]
    }
   ],
   "source": [
    "ACC = get_results(model, criterion, clnloader, device)\n",
    "ASR = get_results(model, criterion, poiloader, device)\n",
    "\n",
    "print('Original ACC:', ACC)\n",
    "print('Original ASR:', ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77be9557-f163-47f2-a069-996d7c942d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the inner loss L2\n",
    "def loss_inner(perturb, model_params):\n",
    "    images = images_list[0].cuda()\n",
    "    labels = labels_list[0].long().cuda()\n",
    "#     per_img = torch.clamp(images+perturb[0],min=0,max=1)\n",
    "    per_img = images+perturb[0]\n",
    "    per_logits = model.forward(per_img)\n",
    "    loss = F.cross_entropy(per_logits, labels, reduction='none')\n",
    "    loss_regu = torch.mean(-loss) +0.001*torch.pow(torch.norm(perturb[0]),2)\n",
    "    return loss_regu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d77a1e-f1f0-4b87-865f-37ac71cc8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the outer loss L1\n",
    "def loss_outer(perturb, model_params):\n",
    "    portion = 0.01\n",
    "    images, labels = images_list[batchnum].cuda(), labels_list[batchnum].long().cuda()\n",
    "    patching = torch.zeros_like(images, device='cuda')\n",
    "    number = images.shape[0]\n",
    "    rand_idx = random.sample(list(np.arange(number)),int(number*portion))\n",
    "    patching[rand_idx] = perturb[0]\n",
    "#     unlearn_imgs = torch.clamp(images+patching,min=0,max=1)\n",
    "    unlearn_imgs = images+patching\n",
    "    logits = model(unlearn_imgs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1ebafa-4aa5-43b3-9737-0fcb28dd5a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list, labels_list = [], []\n",
    "for index, (images, labels) in enumerate(unlloader):\n",
    "    images_list.append(images)\n",
    "    labels_list.append(labels)\n",
    "inner_opt = hg.GradientDescent(loss_inner, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28507f91-bb95-494c-8145-88a604f03104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting Defence\n"
     ]
    }
   ],
   "source": [
    "#inner loop and optimization by batch computing\n",
    "import tqdm\n",
    "print(\"Conducting Defence\")\n",
    "\n",
    "ASR_list = [get_results(model, criterion, poiloader, device)]\n",
    "ACC_list = [get_results(model, criterion, clnloader, device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37e6c7a0-4f1e-4e90-a3cc-a455adb6d22f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\n",
      "ACC: 0.8824\n",
      "ASR: 0.37555555555555553\n",
      "Round: 1\n",
      "ACC: 0.8798\n",
      "ASR: 0.206\n",
      "Round: 2\n",
      "ACC: 0.8878\n",
      "ASR: 0.40155555555555555\n",
      "Round: 3\n",
      "ACC: 0.8738\n",
      "ASR: 0.3556666666666667\n",
      "Round: 4\n",
      "ACC: 0.8776\n",
      "ASR: 0.7017777777777777\n",
      "Round: 5\n",
      "ACC: 0.866\n",
      "ASR: 0.2613333333333333\n",
      "Round: 6\n",
      "ACC: 0.8868\n",
      "ASR: 0.6607777777777778\n",
      "Round: 7\n",
      "ACC: 0.8818\n",
      "ASR: 0.708\n",
      "Round: 8\n",
      "ACC: 0.8686\n",
      "ASR: 0.5197777777777778\n",
      "Round: 9\n",
      "ACC: 0.8686\n",
      "ASR: 0.753\n",
      "Round: 10\n",
      "ACC: 0.8672\n",
      "ASR: 0.2772222222222222\n",
      "Round: 11\n",
      "ACC: 0.885\n",
      "ASR: 0.5254444444444445\n",
      "Round: 12\n",
      "ACC: 0.8822\n",
      "ASR: 0.4557777777777778\n",
      "Round: 13\n",
      "ACC: 0.8828\n",
      "ASR: 0.6277777777777778\n",
      "Round: 14\n",
      "ACC: 0.8736\n",
      "ASR: 0.5633333333333334\n",
      "Round: 15\n",
      "ACC: 0.8658\n",
      "ASR: 0.5988888888888889\n",
      "Round: 16\n",
      "ACC: 0.865\n",
      "ASR: 0.4666666666666667\n",
      "Round: 17\n",
      "ACC: 0.873\n",
      "ASR: 0.6015555555555555\n",
      "Round: 18\n",
      "ACC: 0.8696\n",
      "ASR: 0.47333333333333333\n",
      "Round: 19\n",
      "ACC: 0.8706\n",
      "ASR: 0.6451111111111111\n",
      "Round: 20\n",
      "ACC: 0.866\n",
      "ASR: 0.6044444444444445\n",
      "Round: 21\n",
      "ACC: 0.8676\n",
      "ASR: 0.4241111111111111\n",
      "Round: 22\n",
      "ACC: 0.8694\n",
      "ASR: 0.4912222222222222\n",
      "Round: 23\n",
      "ACC: 0.8594\n",
      "ASR: 0.3184444444444444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_933886/2249130934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatchnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mhg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_outer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/workplace/ziyuan/BackdoorSDNs/I-BAU/hypergrad.py\u001b[0m in \u001b[0;36mfixed_point\u001b[0;34m(params, hparams, K, fp_map, outer_loss, tol, set_grad, stochastic)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mw_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_mapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outer_hparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1_10/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_path = '../BackdoorSDN/models/vgg16_cifar10/BAU'\n",
    "for round in range(100): #K\n",
    "    batch_pert = torch.zeros_like(x_test[:1], requires_grad=True, device='cuda')\n",
    "    batch_opt = torch.optim.SGD(params=[batch_pert],lr=10)\n",
    "   \n",
    "    for images, labels in unlloader:\n",
    "        images = images.to(device)\n",
    "        ori_lab = torch.argmax(model.forward(images),axis = 1).long()\n",
    "#         per_logits = model.forward(torch.clamp(images+batch_pert,min=0,max=1))\n",
    "        per_logits = model.forward(images+batch_pert)\n",
    "        loss = F.cross_entropy(per_logits, ori_lab, reduction='mean')\n",
    "        loss_regu = torch.mean(-loss) +0.001*torch.pow(torch.norm(batch_pert),2)\n",
    "        batch_opt.zero_grad()\n",
    "        loss_regu.backward(retain_graph = True)\n",
    "        batch_opt.step()\n",
    "\n",
    "    #l2-ball\n",
    "    pert = batch_pert * min(1, 10 / torch.norm(batch_pert))\n",
    "\n",
    "    #unlearn step         \n",
    "    for batchnum in range(len(images_list)): #T\n",
    "        outer_opt.zero_grad()\n",
    "        hg.fixed_point(pert, list(model.parameters()), 5, inner_opt, loss_outer) \n",
    "        outer_opt.step()\n",
    "\n",
    "    ASR_list.append(get_results(model,criterion,poiloader,device))\n",
    "    ACC_list.append(get_results(model,criterion,clnloader,device))\n",
    "    print('Round:',round)\n",
    "    \n",
    "    print('ACC:',get_results(model,criterion,clnloader,device))\n",
    "    print('ASR:',get_results(model,criterion,poiloader,device))\n",
    "    \n",
    "    save_f = int((round+1)/10)\n",
    "    if (round+1)%10 == 0:\n",
    "        save_path = os.path.join(result_path, \"BAU_cnn_{}.pt\".format(save_f))\n",
    "        torch.save(model.state_dict(), save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Feb 24 2021, 15:54:32) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b0bbc59db77a5db02c1228c60e342842de780909f41ac452708e93806f71d31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
